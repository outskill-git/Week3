{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "V3SNDff3mHIe",
      "metadata": {
        "id": "V3SNDff3mHIe"
      },
      "source": [
        " ü§ñ My First Groq-Powered Coding Assistant (Notebook Edition)\n",
        "\n",
        "Welcome! This Jupyter Notebook will guide you through creating a simple coding assistant that uses the Groq API for fast responses from Large Language Models (LLMs) like Llama 3.\n",
        "\n",
        "**What you'll learn:**\n",
        "- How to install and import necessary Python libraries.\n",
        "- How to securely configure your Groq API key.\n",
        "- How to connect to the Groq service.\n",
        "- How to send prompts to an LLM and get responses.\n",
        "- How to use \"tools\" (like getting the current time) with the LLM.\n",
        "- How to evaluate the LLM's responses.\n",
        "- How to create a basic interactive chat loop.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yDlnj02pmHIg",
      "metadata": {
        "id": "yDlnj02pmHIg"
      },
      "source": [
        "## ‚öôÔ∏è Step 0: Setup - Install Libraries\n",
        "\n",
        "First, we need to make sure we have the `groq` library (for interacting with the Groq API) and `python-dotenv` (for managing our API key securely).\n",
        "\n",
        "**Instructions:**\n",
        "1. Run the code cell below **once**.\n",
        "2. If the libraries are already installed, it won't do any harm.\n",
        "3. After running it successfully, you can comment out the `!pip install` lines (by adding a `#` at the beginning of those lines) to avoid running them every time you open the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gRjSm2YLmHIg",
      "metadata": {
        "id": "gRjSm2YLmHIg"
      },
      "outputs": [],
      "source": [
        "# Before running this, make sure you have Python installed.\n",
        "# You can run these commands in your terminal or directly in a notebook cell by adding \"!\" at the beginning.\n",
        "# If you run them here, they only need to be run once.\n",
        "\n",
        "# print(\"Installing necessary libraries...\")\n",
        "# !pip install groq python-dotenv\n",
        "\n",
        "# print(\"Installation complete! You can now comment out the !pip install lines or remove this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9PUX1XFwmHIh",
      "metadata": {
        "id": "9PUX1XFwmHIh"
      },
      "source": [
        "Now, let's import the libraries we'll need for this project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Lal5NYowmHIh",
      "metadata": {
        "id": "Lal5NYowmHIh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from groq import Groq, RateLimitError, APIError\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv # For loading API key from a .env file\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4hOj3rQAmHIh",
      "metadata": {
        "id": "4hOj3rQAmHIh"
      },
      "source": [
        "## üîë Step 1: Configure Your Groq API Key\n",
        "\n",
        "To use the Groq API, you need an API key. You can get one from the [Groq Console](https://console.groq.com/keys).\n",
        "\n",
        "\n",
        "**For Local Jupyter:**\n",
        "1.  **Create a file named `.env`** in the *same directory* as this notebook.\n",
        "2.  Open the `.env` file with a text editor.\n",
        "3.  Add the following line, replacing `your_gsk_key_here` with your actual Groq API key:\n",
        "    ```\n",
        "    GROQ_API_KEY=\"your_gsk_key_here\"\n",
        "    ```\n",
        "4.  Save the `.env` file.\n",
        "\n",
        "**For Google Colab (Preferred for Colab):**\n",
        "1. Click the **key icon (üîë)** in the left sidebar of Colab.\n",
        "2. Click `+ ADD A NEW SECRET`.\n",
        "3. Name: `GROQ_API_KEY`\n",
        "4. Value: Your actual Groq API key.\n",
        "5. Ensure 'Notebook access' is ON.\n",
        "The code in the next cell is set up for local `.env` but will need adjustment for Colab secrets (see Colab instructions I provided earlier)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "XvyfmGa_mHIh",
      "metadata": {
        "id": "XvyfmGa_mHIh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Groq API Key loaded (or attempted from environment/Colab Secrets).\n",
            "Using model: llama3-8b-8192\n",
            "Using evaluation model: llama3-8b-8192\n"
          ]
        }
      ],
      "source": [
        "# Load environment variables from .env file (for local use)\n",
        "# For Colab, you'd use: from google.colab import userdata; GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "load_dotenv()\n",
        "\n",
        "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")\n",
        "\n",
        "if not GROQ_API_KEY:\n",
        "    print(\"GROQ_API_KEY not found. Ensure it's in .env (local) or Colab Secrets and you've adapted this cell if in Colab.\")\n",
        "    # Fallback for manual input if needed, but not recommended for routine use:\n",
        "    # GROQ_API_KEY = input(\"Please enter your Groq API Key: \")\n",
        "    if not GROQ_API_KEY: # Check again if it was entered\n",
        "        raise ValueError(\n",
        "            \"Groq API Key is not set. Please configure it and restart the kernel.\"\n",
        "        )\n",
        "else:\n",
        "    print(\"Groq API Key loaded (or attempted from environment/Colab Secrets).\")\n",
        "\n",
        "# --- Configuration ---\n",
        "DEFAULT_MODEL = \"llama3-8b-8192\"\n",
        "EVALUATION_MODEL = \"llama3-8b-8192\" # Can be the same or different\n",
        "\n",
        "print(f\"Using model: {DEFAULT_MODEL}\")\n",
        "print(f\"Using evaluation model: {EVALUATION_MODEL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5_R1UWXamHIi",
      "metadata": {
        "id": "5_R1UWXamHIi"
      },
      "source": [
        "## üîó Step 2: Connect to the Groq Client\n",
        "\n",
        "Now that we have the API key, let's write a function to initialize the Groq client. This client is what we'll use to communicate with the Groq API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8-QsyNtCmHIi",
      "metadata": {
        "id": "8-QsyNtCmHIi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Groq client initialized successfully.\n",
            "Successfully connected to Groq!\n"
          ]
        }
      ],
      "source": [
        "def get_groq_client():\n",
        "    \"\"\"Initializes and returns the Groq client.\"\"\"\n",
        "    if not GROQ_API_KEY:\n",
        "        print(\n",
        "            \"Groq API Key not found. Please ensure it's set.\"\n",
        "        )\n",
        "        return None\n",
        "    try:\n",
        "        client = Groq(api_key=GROQ_API_KEY)\n",
        "        print(\"Groq client initialized successfully.\")\n",
        "        return client\n",
        "    except APIError as e:\n",
        "        print(f\"Failed to initialize Groq client due to APIError: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during client initialization: {e}\")\n",
        "        return None\n",
        "\n",
        "# Attempt to initialize the client\n",
        "groq_client = get_groq_client()\n",
        "\n",
        "if groq_client:\n",
        "    print(\"Successfully connected to Groq!\")\n",
        "else:\n",
        "    print(\"Failed to connect to Groq. Please check your API key and network connection.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qoIDLZ-YmHIi",
      "metadata": {
        "id": "qoIDLZ-YmHIi"
      },
      "source": [
        "## üõ†Ô∏è Step 3: Define Helper Functions\n",
        "\n",
        "We need a few helper functions:\n",
        "1.  `get_current_datetime`: An example function that the LLM can \"call\" if it needs the current time to answer a coding question.\n",
        "2.  `filter_messages_for_api`: This function ensures we only send data to the API that it expects, removing any custom keys we might add for our own use (like evaluation results)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cD8culvOmHIi",
      "metadata": {
        "id": "cD8culvOmHIi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions defined.\n"
          ]
        }
      ],
      "source": [
        "def get_current_datetime():\n",
        "    \"\"\"Returns the current date and time as a JSON string.\"\"\"\n",
        "    return json.dumps({\"current_datetime\": datetime.now().isoformat()})\n",
        "\n",
        "def filter_messages_for_api(messages):\n",
        "    \"\"\"Removes custom keys like 'evaluation' before sending to API.\"\"\"\n",
        "    api_messages = []\n",
        "    for msg in messages:\n",
        "        api_msg = msg.copy()\n",
        "        api_msg.pop(\"evaluation\", None)\n",
        "        api_messages.append(api_msg)\n",
        "    return api_messages\n",
        "\n",
        "print(\"Helper functions defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbGART19mHIi",
      "metadata": {
        "id": "dbGART19mHIi"
      },
      "source": [
        "## üí¨ Step 4: Interacting with the LLM - `run_conversation`\n",
        "\n",
        "This is the core function that sends our messages to the LLM and gets a response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Jh3P0tC_mHIi",
      "metadata": {
        "id": "Jh3P0tC_mHIi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`run_conversation` function defined.\n"
          ]
        }
      ],
      "source": [
        "def run_conversation(client, messages, model, tools=None, tool_choice=\"auto\"):\n",
        "    if not client:\n",
        "        print(\"Groq client is not initialized. Cannot run conversation.\")\n",
        "        return None\n",
        "\n",
        "    system_prompt = {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"You are a specialized Coding Assistant AI.\n",
        "        Your primary function is to help users with programming and coding-related questions.\n",
        "        Strictly adhere to the following rules:\n",
        "        1. ONLY answer questions directly related to coding, programming languages, algorithms, data structures, software development tools, and concepts.\n",
        "        2. If the user asks a question NOT related to coding, politely refuse to answer. State clearly that you can only assist with coding topics. Example refusal: \"I specialize in coding-related questions. I cannot help with [topic of user's query].\"\n",
        "        3. Provide clear, concise, and accurate coding explanations or code snippets.\n",
        "        4. If you need the current date or time to answer a coding-related question (e.g., about library versions released after a certain date), you can use the available 'get_current_datetime' function. Do not use it for non-coding purposes.\n",
        "        5. Do not invent information. If you don't know the answer, say so.\n",
        "        \"\"\",\n",
        "    }\n",
        "    conversation_history = [system_prompt] + messages\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=conversation_history,\n",
        "            temperature=0.7,\n",
        "            tools=tools,\n",
        "            tool_choice=tool_choice,\n",
        "        )\n",
        "        return response.choices[0].message\n",
        "    except RateLimitError:\n",
        "        print(\"Rate limit reached. Please wait and try again.\")\n",
        "        return None\n",
        "    except APIError as e:\n",
        "        print(f\"Groq API Error: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during conversation: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"`run_conversation` function defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2liSC13FmHIj",
      "metadata": {
        "id": "2liSC13FmHIj"
      },
      "source": [
        "## üîß Step 5: Defining Tools for the LLM\n",
        "\n",
        "LLMs can be given access to \"tools\" (functions) that they can use to get information or perform actions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "AJ6BrWAcmHIj",
      "metadata": {
        "id": "AJ6BrWAcmHIj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tools schema and available tools defined.\n"
          ]
        }
      ],
      "source": [
        "available_tools = {\n",
        "    \"get_current_datetime\": get_current_datetime,\n",
        "}\n",
        "\n",
        "tools_schema = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_datetime\",\n",
        "            \"description\": \"Get the current date and time as an ISO formatted string in JSON. Useful for time-sensitive coding questions. Only use if specifically needed for a coding context.\",\n",
        "            \"parameters\": {\n",
        "                 \"type\": \"object\",\n",
        "                 \"properties\": {},\n",
        "                 \"required\": [],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"Tools schema and available tools defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qtHXKaeZmHIj",
      "metadata": {
        "id": "qtHXKaeZmHIj"
      },
      "source": [
        "## üìä Step 6: Evaluating the Assistant's Response\n",
        "\n",
        "This function will use another LLM call to assess the relevance and helpfulness of the assistant's response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "_Ld7wqSGmHIj",
      "metadata": {
        "id": "_Ld7wqSGmHIj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`evaluate_response` function defined.\n"
          ]
        }
      ],
      "source": [
        "def evaluate_response(client, user_query, assistant_response_content, model):\n",
        "    if not client:\n",
        "        print(\"Groq client is not initialized. Cannot evaluate response.\")\n",
        "        return \"Evaluation failed (client not initialized).\"\n",
        "\n",
        "    eval_system_prompt_content = f\"\"\"You are an evaluation AI. Evaluate the assistant's response based on the user's query.\n",
        "    User Query: \"{user_query}\"\n",
        "    Assistant Response: \"{assistant_response_content}\"\n",
        "\n",
        "    Evaluate based on these criteria:\n",
        "    1.  **Coding Relevance:** Was the assistant's response strictly related to coding/programming topics? (Yes/No)\n",
        "    2.  **Helpfulness (if relevant):** If the response was coding-related, how helpful and accurate was it? (Score 1-5, 5=Excellent, 1=Not Helpful, NA if not relevant)\n",
        "    3.  **Refusal Appropriateness (if irrelevant):** If the user's query was *not* coding-related, did the assistant politely refuse according to its instructions? (Yes/No/NA)\n",
        "\n",
        "    Provide the evaluation concisely, starting with \"Evaluation:\".\n",
        "    Example (Relevant): \"Evaluation: Coding Relevance: Yes, Helpfulness: 4/5, Refusal Appropriateness: NA\"\n",
        "    Example (Irrelevant, Correct Refusal): \"Evaluation: Coding Relevance: No, Helpfulness: NA, Refusal Appropriateness: Yes\"\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"system\", \"content\": eval_system_prompt_content}],\n",
        "            temperature=0.1,\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except RateLimitError:\n",
        "        print(\"Evaluation failed due to rate limit.\")\n",
        "        return \"Evaluation failed (Rate Limit).\"\n",
        "    except APIError as e:\n",
        "        print(f\"Could not evaluate the response due to API error: {e}\")\n",
        "        return f\"Evaluation failed (API Error: {e}).\"\n",
        "    except Exception as e:\n",
        "        print(f\"Could not evaluate the response: {e}\")\n",
        "        return f\"Evaluation failed ({type(e).__name__}).\"\n",
        "\n",
        "print(\"`evaluate_response` function defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B2Y2wLsamHIj",
      "metadata": {
        "id": "B2Y2wLsamHIj"
      },
      "source": [
        "## üó£Ô∏è Step 7: Let's Chat! - Interactive Mode\n",
        "\n",
        "- Type your coding question and press Enter.\n",
        "- Type `quit`, `exit`, or `bye` to end the chat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ySeLqrQymHIj",
      "metadata": {
        "id": "ySeLqrQymHIj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Interactive Chat with the Coding Assistant ---\n",
            "Type 'quit', 'exit', or 'bye' to end the session.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "if not groq_client:\n",
        "    print(\"Cannot start chat: Groq client is not initialized. Please check previous steps.\")\n",
        "else:\n",
        "    print(\"\\n--- Starting Interactive Chat with the Coding Assistant ---\")\n",
        "    print(\"Type 'quit', 'exit', or 'bye' to end the session.\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    chat_history = []\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "            print(\"\\nAssistant: Goodbye! üëã\")\n",
        "            break\n",
        "\n",
        "        if not user_input.strip():\n",
        "            continue\n",
        "\n",
        "        chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "        print(\"\\nAssistant: üß† Thinking...\")\n",
        "        messages_for_api_call = filter_messages_for_api(chat_history)\n",
        "\n",
        "        response_message = run_conversation(\n",
        "            client=groq_client,\n",
        "            messages=messages_for_api_call,\n",
        "            model=DEFAULT_MODEL,\n",
        "            tools=tools_schema,\n",
        "            tool_choice=\"auto\",\n",
        "        )\n",
        "\n",
        "        assistant_response_content = \"\"\n",
        "        assistant_message_for_history = {}\n",
        "\n",
        "        if response_message:\n",
        "            if response_message.tool_calls:\n",
        "                print(\"Assistant: üõ†Ô∏è Function call requested...\")\n",
        "                chat_history.append(response_message.model_dump(exclude_unset=True))\n",
        "                tool_results_for_api = []\n",
        "                for tool_call in response_message.tool_calls:\n",
        "                    function_name = tool_call.function.name\n",
        "                    tool_call_id = tool_call.id\n",
        "                    print(f\"Assistant: Attempting to call function: {function_name}\")\n",
        "                    if function_name in available_tools:\n",
        "                        function_to_call = available_tools[function_name]\n",
        "                        try:\n",
        "                            function_response_content = function_to_call()\n",
        "                            tool_results_for_api.append(\n",
        "                                {\n",
        "                                    \"tool_call_id\": tool_call_id,\n",
        "                                    \"role\": \"tool\",\n",
        "                                    \"name\": function_name,\n",
        "                                    \"content\": function_response_content,\n",
        "                                }\n",
        "                            )\n",
        "                            print(f\"Assistant: Function '{function_name}' executed.\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error executing function {function_name}: {e}\")\n",
        "                            tool_results_for_api.append(\n",
        "                                 {\n",
        "                                    \"tool_call_id\": tool_call_id,\n",
        "                                    \"role\": \"tool\",\n",
        "                                    \"name\": function_name,\n",
        "                                    \"content\": f\"Error executing function: {e}\",\n",
        "                                }\n",
        "                            )\n",
        "                    else:\n",
        "                         print(f\"Assistant: Error - Function '{function_name}' not found.\")\n",
        "                         tool_results_for_api.append(\n",
        "                            {\n",
        "                                \"tool_call_id\": tool_call_id,\n",
        "                                \"role\": \"tool\",\n",
        "                                \"name\": function_name,\n",
        "                                \"content\": f\"Error: Function '{function_name}' is not defined.\",\n",
        "                            }\n",
        "                        )\n",
        "                chat_history.extend(tool_results_for_api)\n",
        "                print(\"Assistant: ‚öôÔ∏è Processing function results...\")\n",
        "                messages_for_api_call_2 = filter_messages_for_api(chat_history)\n",
        "                final_response_message = run_conversation(\n",
        "                    client=groq_client,\n",
        "                    messages=messages_for_api_call_2,\n",
        "                    model=DEFAULT_MODEL,\n",
        "                    tool_choice=\"none\",\n",
        "                )\n",
        "                if final_response_message and final_response_message.content:\n",
        "                    assistant_response_content = final_response_message.content\n",
        "                    assistant_message_for_history = final_response_message.model_dump(exclude_unset=True)\n",
        "                else:\n",
        "                    assistant_response_content = \"Sorry, I encountered an error after processing the function call.\"\n",
        "                    assistant_message_for_history = {\"role\": \"assistant\", \"content\": assistant_response_content}\n",
        "            else:\n",
        "                if response_message.content:\n",
        "                    assistant_response_content = response_message.content\n",
        "                    assistant_message_for_history = response_message.model_dump(exclude_unset=True)\n",
        "                else:\n",
        "                    assistant_response_content = \"Sorry, I received an unexpected empty response.\"\n",
        "                    assistant_message_for_history = {\"role\": \"assistant\", \"content\": assistant_response_content}\n",
        "        else:\n",
        "            assistant_response_content = \"Sorry, I couldn't get a response due to an error.\"\n",
        "            assistant_message_for_history = {\"role\": \"assistant\", \"content\": assistant_response_content}\n",
        "\n",
        "        if assistant_message_for_history:\n",
        "            chat_history.append(assistant_message_for_history)\n",
        "\n",
        "        print(f\"\\nAssistant: {assistant_response_content}\")\n",
        "\n",
        "        if assistant_response_content and not assistant_response_content.startswith(\"Sorry\"):\n",
        "            print(\"\\nAssistant: üìä Evaluating response...\")\n",
        "            evaluation_result = evaluate_response(\n",
        "                client=groq_client,\n",
        "                user_query=user_input,\n",
        "                assistant_response_content=assistant_response_content,\n",
        "                model=EVALUATION_MODEL,\n",
        "            )\n",
        "            print(f\"Assistant [Evaluation]: {evaluation_result}\")\n",
        "            if chat_history and chat_history[-1][\"role\"] == \"assistant\":\n",
        "                 chat_history[-1][\"evaluation\"] = evaluation_result\n",
        "        else:\n",
        "            print(\"\\nAssistant [Evaluation]: Skipped.\")\n",
        "\n",
        "        print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hupRDqXamHIj",
      "metadata": {
        "id": "hupRDqXamHIj"
      },
      "source": [
        "## üéâ Congratulations!\n",
        "\n",
        "You've successfully set up and interacted with a Groq-powered Coding Assistant!\n",
        "\n",
        "**Next Steps & Ideas:**\n",
        "- Try different coding questions.\n",
        "- Ask a non-coding question to see the refusal.\n",
        "- Experiment with models and tools."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
